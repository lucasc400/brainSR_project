{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1595497794506,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "wrYMOg460g4e",
    "outputId": "f1bd62bc-962d-4a7f-a6d9-1e920d85e427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1595497797497,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "rog6A4vl0kkL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('gdrive/My Drive/Super_resolution/brainSR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554144,
     "status": "ok",
     "timestamp": 1595498352022,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "NjGIWrCg1Evx"
   },
   "outputs": [],
   "source": [
    "from data.image_list import create_image_list\n",
    "from data.dataset import create_dataset\n",
    "from data.data_loader import create_dataloader\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from math import log10\n",
    "from utils import util, convert, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1595498487409,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "64ZmMNTy1U69"
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"SRResNet_x4\",\n",
    "    \"model\": \"sr_resnet\",\n",
    "    \"gpu_ids\": [0],\n",
    "    \"upscale_factor\":4,\n",
    "    \"device\": \"cuda\",\n",
    "\n",
    "    \"datasets\":\n",
    "        {\n",
    "            \"path\":\n",
    "                {\n",
    "                \"root\": \"data/BrainTumour\",\n",
    "                \"folders\": [\"imagesTr\", \"imagesTs\"]\n",
    "                },\n",
    "            \"train\":\n",
    "                {\n",
    "                \"phase\": \"train\",\n",
    "                \"batch_size\": 64,\n",
    "                \"use_shuffle\": True,\n",
    "                \"upscale_factor\": 4,\n",
    "                \"scale\": True,\n",
    "                # \"transform_H\": {},\n",
    "                \"no_of_images\": 725,\n",
    "                \"n_workers\": 1\n",
    "                },\n",
    "            \"valid\":\n",
    "                {\n",
    "                \"phase\": \"valid\",\n",
    "                \"no_of_images\": 25,\n",
    "                \"scale\": True,\n",
    "                \"depth_padding\": 1,\n",
    "                \"upscale_factor\": 4                \n",
    "                # \"transform_H\": {}\n",
    "                }\n",
    "    },\n",
    "\n",
    "    \n",
    "  \"path\": \n",
    "    {\n",
    "        \"root\": \"\"\n",
    "    },\n",
    "\n",
    "  \"network\":\n",
    "    {\n",
    "        \"norm_type\": \"batch\",\n",
    "        \"which_model_G\": \"sr_resnet\",\n",
    "        \"ngf\": 64,\n",
    "        \"ngb\": 16,\n",
    "        \"input_ngc\": 1,\n",
    "        \"output_ngc\": 1\n",
    "    },\n",
    "\n",
    "  \"train\" : \n",
    "    {\n",
    "        \"manual_seed\": 777,\n",
    "        \"niter\": 30,\n",
    "        \"val_freq\": 5,\n",
    "        \"lr_G\": 1e-4,\n",
    "        \"criterion\": \"mse\"\n",
    "    },\n",
    "\n",
    "\n",
    "    \"logger\": \n",
    "    {\n",
    "        \"print_freq\": 100,\n",
    "        \"save_checkpoint_freq\": 5\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1595498494260,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "g9cJmGu41pE9"
   },
   "outputs": [],
   "source": [
    "def parse(opt_path, is_train=True):\n",
    "#     with open(opt_path, 'r') as f:\n",
    "#         opt = json.load(f, object_pairs_hook=OrderedDict)\n",
    "    opt['is_train'] = is_train\n",
    "\n",
    "    for key, path in opt['path'].items():\n",
    "        opt['path'][key] = os.path.expanduser(path)\n",
    "    if is_train:\n",
    "        experiments_root = os.path.join(opt['path']['root'], 'experiments', opt['name'])\n",
    "        opt['path']['experiments_root'] = experiments_root\n",
    "        opt['path']['options'] = experiments_root\n",
    "        opt['path']['trained_models'] = os.path.join(experiments_root, 'trained_models')\n",
    "        opt['path']['log'] = os.path.join(experiments_root, 'log')\n",
    "    else:\n",
    "        results_root = os.path.join(opt['path']['root'], 'results', opt['name'])\n",
    "        opt['path']['results_root'] = results_root\n",
    "        opt['path']['log'] = os.path.join(results_root, 'log')\n",
    "        opt['path']['test_images'] = os.path.join(results_root, 'test_images')\n",
    "\n",
    "    return opt\n",
    "\n",
    "opt = parse(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 339612,
     "status": "ok",
     "timestamp": 1595498834930,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "6FV3xx6f2I3m",
    "outputId": "9b321d56-e306-4c24-b973-4633c5cc5fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/725 images loaded\n",
      "50/725 images loaded\n",
      "100/725 images loaded\n",
      "150/725 images loaded\n",
      "200/725 images loaded\n",
      "250/725 images loaded\n",
      "300/725 images loaded\n",
      "350/725 images loaded\n",
      "400/725 images loaded\n",
      "450/725 images loaded\n",
      "500/725 images loaded\n",
      "550/725 images loaded\n",
      "600/725 images loaded\n",
      "650/725 images loaded\n",
      "700/725 images loaded\n",
      "0/25 images loaded\n"
     ]
    }
   ],
   "source": [
    "training_image_list = create_image_list(opt, train=True)\n",
    "valid_image_list = create_image_list(opt, valid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1595498998053,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "ypjleCJu2KAP"
   },
   "outputs": [],
   "source": [
    "training_set = create_dataset(opt[\"datasets\"][\"train\"], training_image_list)\n",
    "valid_set = create_dataset(opt[\"datasets\"][\"valid\"], valid_image_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13927,
     "status": "ok",
     "timestamp": 1595499011948,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "US42ry3RvAVP",
    "outputId": "aa07b275-1eae-4807-f76f-558123ea709f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Super_resolution/brainSR/models/modules/block.py:150: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(self.C.weight, a=a, mode='fan_in')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Model initialized -------------\n",
      "Number of parameters in G: 1528724\n",
      "-----------------------------------------------\n",
      "Model [SRResNetModel] is created.\n"
     ]
    }
   ],
   "source": [
    "from models.models import create_model\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1595499105572,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "XihMRf6F4Ttz"
   },
   "outputs": [],
   "source": [
    "from utils.logger import Logger\n",
    "logger = Logger(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1595499105574,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "Bwi12SoT4VMH"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, val_size, depth, model, logger, epoch, current_step):\n",
    "    print('Start validation phase ...')\n",
    "    val_start_time = time.time()\n",
    "    model.eval() # Change to eval mode. It is important for BN layers.\n",
    "\n",
    "    val_results = OrderedDict()\n",
    "    avg_psnr = 0.0 \n",
    "    for val_data in val_loader:\n",
    "        # img_path = val_data['path'][0]\n",
    "        # img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        # img_dir = os.path.join(opt['path']['root'], 'valid', img_name)\n",
    "        # util.mkdir(img_dir)\n",
    "        for slice_no in range(depth):\n",
    "          val_data_slice = dict(H=val_data['H'][slice_no,:,:,:].unsqueeze(0),\n",
    "                                L=val_data['L'][slice_no,:,:,:].unsqueeze(0))\n",
    "          model.feed_data(val_data_slice)\n",
    "          model.val()\n",
    "\n",
    "          visuals = model.get_current_visuals()\n",
    "          \n",
    "          sr_img = visuals['super-resolution'] # uint8\n",
    "          gt_img = visuals['ground-truth'] # uint8\n",
    "\n",
    "          mse = model.criterion(sr_img, gt_img).item()\n",
    "          psnr = 10 * log10(1 / mse)\n",
    "          avg_psnr += psnr\n",
    "\n",
    "    avg_psnr = avg_psnr / val_size / depth\n",
    "    val_results['psnr'] = avg_psnr\n",
    "\n",
    "    val_duration = time.time() - val_start_time\n",
    "    # Save to log\n",
    "    logger.print_results(val_results, epoch, current_step, val_duration, 'val')\n",
    "    model.train() # Change back to train mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BEiaKZkm4-Jd",
    "outputId": "af9283a2-7f33-4c44-a8be-873453dc16e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch:   0, iters:        0, time: 0.771) loss: 0.787772 \n",
      "(epoch:   0, iters:      100, time: 0.751) loss: 0.008760 \n",
      "(epoch:   0, iters:      200, time: 0.751) loss: 0.004576 \n",
      "(epoch:   0, iters:      300, time: 0.750) loss: 0.003137 \n",
      "(epoch:   0, iters:      400, time: 0.751) loss: 0.003046 \n",
      "(epoch:   0, iters:      500, time: 0.755) loss: 0.001649 \n",
      "(epoch:   0, iters:      600, time: 0.753) loss: 0.002698 \n",
      "(epoch:   0, iters:      700, time: 0.753) loss: 0.002341 \n",
      "end of iteration 0\n",
      "(epoch:   1, iters:        0, time: 0.750) loss: 0.001461 \n",
      "(epoch:   1, iters:      100, time: 0.750) loss: 0.001399 \n",
      "(epoch:   1, iters:      200, time: 0.750) loss: 0.001242 \n",
      "(epoch:   1, iters:      300, time: 0.756) loss: 0.001412 \n",
      "(epoch:   1, iters:      400, time: 0.753) loss: 0.001344 \n",
      "(epoch:   1, iters:      500, time: 0.750) loss: 0.000988 \n",
      "(epoch:   1, iters:      600, time: 0.750) loss: 0.001349 \n",
      "(epoch:   1, iters:      700, time: 0.753) loss: 0.001351 \n",
      "end of iteration 1\n",
      "(epoch:   2, iters:        0, time: 0.751) loss: 0.000805 \n",
      "(epoch:   2, iters:      100, time: 0.751) loss: 0.000864 \n",
      "(epoch:   2, iters:      200, time: 0.751) loss: 0.000867 \n",
      "(epoch:   2, iters:      300, time: 0.752) loss: 0.001137 \n",
      "(epoch:   2, iters:      400, time: 0.748) loss: 0.001158 \n",
      "(epoch:   2, iters:      500, time: 0.751) loss: 0.000662 \n",
      "(epoch:   2, iters:      600, time: 0.751) loss: 0.000999 \n",
      "(epoch:   2, iters:      700, time: 0.751) loss: 0.001061 \n",
      "end of iteration 2\n",
      "(epoch:   3, iters:        0, time: 0.750) loss: 0.000600 \n",
      "(epoch:   3, iters:      100, time: 0.750) loss: 0.000660 \n",
      "(epoch:   3, iters:      200, time: 0.752) loss: 0.000715 \n",
      "(epoch:   3, iters:      300, time: 0.750) loss: 0.000938 \n",
      "(epoch:   3, iters:      400, time: 0.749) loss: 0.001031 \n",
      "(epoch:   3, iters:      500, time: 0.750) loss: 0.000565 \n",
      "(epoch:   3, iters:      600, time: 0.749) loss: 0.000817 \n",
      "(epoch:   3, iters:      700, time: 0.754) loss: 0.001040 \n",
      "end of iteration 3\n",
      "(epoch:   4, iters:        0, time: 0.754) loss: 0.000531 \n",
      "(epoch:   4, iters:      100, time: 0.750) loss: 0.000708 \n",
      "(epoch:   4, iters:      200, time: 0.750) loss: 0.000629 \n",
      "(epoch:   4, iters:      300, time: 0.750) loss: 0.000922 \n",
      "(epoch:   4, iters:      400, time: 0.750) loss: 0.000939 \n",
      "(epoch:   4, iters:      500, time: 0.749) loss: 0.000552 \n",
      "(epoch:   4, iters:      600, time: 0.751) loss: 0.000807 \n",
      "(epoch:   4, iters:      700, time: 0.750) loss: 0.000995 \n",
      "end of iteration 4\n",
      "(epoch:   5, iters:        0, time: 0.752) loss: 0.000466 \n",
      "(epoch:   5, iters:      100, time: 0.752) loss: 0.000587 \n",
      "(epoch:   5, iters:      200, time: 0.752) loss: 0.000555 \n",
      "(epoch:   5, iters:      300, time: 0.751) loss: 0.000841 \n",
      "(epoch:   5, iters:      400, time: 0.749) loss: 0.000873 \n",
      "(epoch:   5, iters:      500, time: 0.751) loss: 0.000540 \n",
      "(epoch:   5, iters:      600, time: 0.750) loss: 0.000843 \n",
      "(epoch:   5, iters:      700, time: 0.749) loss: 0.000830 \n",
      "Start validation phase ...\n",
      "(epoch:   5, iters:      724, time: 353.938) psnr: 35.375399 \n",
      "Saving the model at the end of iteration 5\n",
      "end of iteration 5\n",
      "(epoch:   6, iters:        0, time: 0.753) loss: 0.000380 \n",
      "(epoch:   6, iters:      100, time: 0.750) loss: 0.000536 \n",
      "(epoch:   6, iters:      200, time: 0.751) loss: 0.000469 \n",
      "(epoch:   6, iters:      300, time: 0.754) loss: 0.000655 \n",
      "(epoch:   6, iters:      400, time: 0.752) loss: 0.000909 \n",
      "(epoch:   6, iters:      500, time: 0.752) loss: 0.000469 \n",
      "(epoch:   6, iters:      600, time: 0.757) loss: 0.000683 \n",
      "(epoch:   6, iters:      700, time: 0.750) loss: 0.000934 \n",
      "end of iteration 6\n",
      "(epoch:   7, iters:        0, time: 0.752) loss: 0.000349 \n",
      "(epoch:   7, iters:      100, time: 0.750) loss: 0.000474 \n",
      "(epoch:   7, iters:      200, time: 0.751) loss: 0.000473 \n",
      "(epoch:   7, iters:      300, time: 0.751) loss: 0.000648 \n",
      "(epoch:   7, iters:      400, time: 0.751) loss: 0.000784 \n",
      "(epoch:   7, iters:      500, time: 0.751) loss: 0.000442 \n",
      "(epoch:   7, iters:      600, time: 0.750) loss: 0.000632 \n",
      "(epoch:   7, iters:      700, time: 0.751) loss: 0.000916 \n",
      "end of iteration 7\n",
      "(epoch:   8, iters:        0, time: 0.755) loss: 0.000380 \n",
      "(epoch:   8, iters:      100, time: 0.751) loss: 0.000525 \n",
      "(epoch:   8, iters:      200, time: 0.750) loss: 0.000427 \n",
      "(epoch:   8, iters:      300, time: 0.751) loss: 0.000666 \n",
      "(epoch:   8, iters:      400, time: 0.751) loss: 0.000735 \n",
      "(epoch:   8, iters:      500, time: 0.752) loss: 0.000433 \n",
      "(epoch:   8, iters:      600, time: 0.750) loss: 0.000595 \n",
      "(epoch:   8, iters:      700, time: 0.751) loss: 0.000781 \n",
      "end of iteration 8\n",
      "(epoch:   9, iters:        0, time: 0.750) loss: 0.000327 \n",
      "(epoch:   9, iters:      100, time: 0.751) loss: 0.000457 \n",
      "(epoch:   9, iters:      200, time: 0.751) loss: 0.000516 \n",
      "(epoch:   9, iters:      300, time: 0.750) loss: 0.000724 \n",
      "(epoch:   9, iters:      400, time: 0.752) loss: 0.000886 \n",
      "(epoch:   9, iters:      500, time: 0.750) loss: 0.000525 \n",
      "(epoch:   9, iters:      600, time: 0.750) loss: 0.000712 \n",
      "(epoch:   9, iters:      700, time: 0.749) loss: 0.000831 \n",
      "end of iteration 9\n",
      "(epoch:  10, iters:        0, time: 0.749) loss: 0.000392 \n",
      "(epoch:  10, iters:      100, time: 0.753) loss: 0.000406 \n",
      "(epoch:  10, iters:      200, time: 0.751) loss: 0.000400 \n",
      "(epoch:  10, iters:      300, time: 0.750) loss: 0.000679 \n",
      "(epoch:  10, iters:      400, time: 0.749) loss: 0.000669 \n",
      "(epoch:  10, iters:      500, time: 0.750) loss: 0.000385 \n",
      "(epoch:  10, iters:      600, time: 0.750) loss: 0.000527 \n",
      "(epoch:  10, iters:      700, time: 0.749) loss: 0.000661 \n",
      "Start validation phase ...\n",
      "(epoch:  10, iters:      724, time: 335.578) psnr: 36.161730 \n",
      "Saving the model at the end of iteration 10\n",
      "end of iteration 10\n",
      "(epoch:  11, iters:        0, time: 0.750) loss: 0.000359 \n",
      "(epoch:  11, iters:      100, time: 0.749) loss: 0.000443 \n",
      "(epoch:  11, iters:      200, time: 0.752) loss: 0.000501 \n",
      "(epoch:  11, iters:      300, time: 0.749) loss: 0.000614 \n",
      "(epoch:  11, iters:      400, time: 0.750) loss: 0.000682 \n",
      "(epoch:  11, iters:      500, time: 0.754) loss: 0.000368 \n",
      "(epoch:  11, iters:      600, time: 0.750) loss: 0.000591 \n",
      "(epoch:  11, iters:      700, time: 0.751) loss: 0.000732 \n",
      "end of iteration 11\n",
      "(epoch:  12, iters:        0, time: 0.749) loss: 0.000301 \n",
      "(epoch:  12, iters:      100, time: 0.750) loss: 0.000413 \n",
      "(epoch:  12, iters:      200, time: 0.751) loss: 0.000731 \n",
      "(epoch:  12, iters:      300, time: 0.749) loss: 0.000655 \n",
      "(epoch:  12, iters:      400, time: 0.749) loss: 0.000651 \n",
      "(epoch:  12, iters:      500, time: 0.750) loss: 0.000368 \n",
      "(epoch:  12, iters:      600, time: 0.752) loss: 0.000568 \n",
      "(epoch:  12, iters:      700, time: 0.750) loss: 0.000700 \n",
      "end of iteration 12\n",
      "(epoch:  13, iters:        0, time: 0.751) loss: 0.000318 \n",
      "(epoch:  13, iters:      100, time: 0.749) loss: 0.000393 \n",
      "(epoch:  13, iters:      200, time: 0.750) loss: 0.000421 \n",
      "(epoch:  13, iters:      300, time: 0.750) loss: 0.000529 \n",
      "(epoch:  13, iters:      400, time: 0.750) loss: 0.000673 \n",
      "(epoch:  13, iters:      500, time: 0.750) loss: 0.000387 \n",
      "(epoch:  13, iters:      600, time: 0.751) loss: 0.000542 \n",
      "(epoch:  13, iters:      700, time: 0.750) loss: 0.000722 \n",
      "end of iteration 13\n",
      "(epoch:  14, iters:        0, time: 0.751) loss: 0.000324 \n",
      "(epoch:  14, iters:      100, time: 0.750) loss: 0.000408 \n",
      "(epoch:  14, iters:      200, time: 0.749) loss: 0.000400 \n",
      "(epoch:  14, iters:      300, time: 0.749) loss: 0.000520 \n",
      "(epoch:  14, iters:      400, time: 0.751) loss: 0.000649 \n",
      "(epoch:  14, iters:      500, time: 0.750) loss: 0.000348 \n",
      "(epoch:  14, iters:      600, time: 0.751) loss: 0.000538 \n",
      "(epoch:  14, iters:      700, time: 0.749) loss: 0.000738 \n",
      "end of iteration 14\n",
      "(epoch:  15, iters:        0, time: 0.750) loss: 0.000288 \n",
      "(epoch:  15, iters:      100, time: 0.750) loss: 0.000341 \n",
      "(epoch:  15, iters:      200, time: 0.750) loss: 0.000390 \n",
      "(epoch:  15, iters:      300, time: 0.749) loss: 0.000689 \n",
      "(epoch:  15, iters:      400, time: 0.751) loss: 0.000627 \n",
      "(epoch:  15, iters:      500, time: 0.750) loss: 0.000379 \n",
      "(epoch:  15, iters:      600, time: 0.750) loss: 0.000520 \n",
      "(epoch:  15, iters:      700, time: 0.751) loss: 0.000659 \n",
      "Start validation phase ...\n",
      "(epoch:  15, iters:      724, time: 341.838) psnr: 36.464731 \n",
      "Saving the model at the end of iteration 15\n",
      "end of iteration 15\n",
      "(epoch:  16, iters:        0, time: 0.756) loss: 0.000260 \n",
      "(epoch:  16, iters:      100, time: 0.753) loss: 0.000391 \n",
      "(epoch:  16, iters:      200, time: 0.751) loss: 0.000282 \n",
      "(epoch:  16, iters:      300, time: 0.751) loss: 0.000606 \n",
      "(epoch:  16, iters:      400, time: 0.750) loss: 0.000612 \n",
      "(epoch:  16, iters:      500, time: 0.751) loss: 0.000353 \n",
      "(epoch:  16, iters:      600, time: 0.750) loss: 0.000453 \n",
      "(epoch:  16, iters:      700, time: 0.751) loss: 0.000612 \n",
      "end of iteration 16\n",
      "(epoch:  17, iters:        0, time: 0.750) loss: 0.000225 \n",
      "(epoch:  17, iters:      100, time: 0.748) loss: 0.000372 \n",
      "(epoch:  17, iters:      200, time: 0.751) loss: 0.000378 \n",
      "(epoch:  17, iters:      300, time: 0.751) loss: 0.000527 \n",
      "(epoch:  17, iters:      400, time: 0.750) loss: 0.000673 \n",
      "(epoch:  17, iters:      500, time: 0.755) loss: 0.000319 \n",
      "(epoch:  17, iters:      600, time: 0.750) loss: 0.000485 \n",
      "(epoch:  17, iters:      700, time: 0.749) loss: 0.000538 \n",
      "end of iteration 17\n",
      "(epoch:  18, iters:        0, time: 0.755) loss: 0.000255 \n",
      "(epoch:  18, iters:      100, time: 0.751) loss: 0.000266 \n",
      "(epoch:  18, iters:      200, time: 0.751) loss: 0.000334 \n",
      "(epoch:  18, iters:      300, time: 0.750) loss: 0.000598 \n",
      "(epoch:  18, iters:      400, time: 0.750) loss: 0.001326 \n",
      "(epoch:  18, iters:      500, time: 0.750) loss: 0.000322 \n",
      "(epoch:  18, iters:      600, time: 0.752) loss: 0.000472 \n",
      "(epoch:  18, iters:      700, time: 0.751) loss: 0.000710 \n",
      "end of iteration 18\n",
      "(epoch:  19, iters:        0, time: 0.750) loss: 0.000257 \n",
      "(epoch:  19, iters:      100, time: 0.749) loss: 0.000406 \n",
      "(epoch:  19, iters:      200, time: 0.751) loss: 0.000452 \n",
      "(epoch:  19, iters:      300, time: 0.751) loss: 0.000516 \n",
      "(epoch:  19, iters:      400, time: 0.752) loss: 0.000580 \n",
      "(epoch:  19, iters:      500, time: 0.751) loss: 0.000337 \n",
      "(epoch:  19, iters:      600, time: 0.750) loss: 0.000470 \n",
      "(epoch:  19, iters:      700, time: 0.750) loss: 0.000710 \n",
      "end of iteration 19\n",
      "(epoch:  20, iters:        0, time: 0.750) loss: 0.000246 \n",
      "(epoch:  20, iters:      100, time: 0.753) loss: 0.000429 \n",
      "(epoch:  20, iters:      200, time: 0.751) loss: 0.000322 \n",
      "(epoch:  20, iters:      300, time: 0.751) loss: 0.000573 \n",
      "(epoch:  20, iters:      400, time: 0.750) loss: 0.000490 \n",
      "(epoch:  20, iters:      500, time: 0.751) loss: 0.000337 \n",
      "(epoch:  20, iters:      600, time: 0.754) loss: 0.000471 \n",
      "(epoch:  20, iters:      700, time: 0.752) loss: 0.000533 \n",
      "Start validation phase ...\n",
      "(epoch:  20, iters:      724, time: 339.828) psnr: 37.929907 \n",
      "Saving the model at the end of iteration 20\n",
      "end of iteration 20\n",
      "(epoch:  21, iters:        0, time: 0.759) loss: 0.000268 \n",
      "(epoch:  21, iters:      100, time: 0.751) loss: 0.000400 \n",
      "(epoch:  21, iters:      200, time: 0.751) loss: 0.000345 \n",
      "(epoch:  21, iters:      300, time: 0.749) loss: 0.000549 \n",
      "(epoch:  21, iters:      400, time: 0.751) loss: 0.000562 \n",
      "(epoch:  21, iters:      500, time: 0.751) loss: 0.000317 \n",
      "(epoch:  21, iters:      600, time: 0.754) loss: 0.000467 \n",
      "(epoch:  21, iters:      700, time: 0.751) loss: 0.000759 \n",
      "end of iteration 21\n",
      "(epoch:  22, iters:        0, time: 0.750) loss: 0.000294 \n",
      "(epoch:  22, iters:      100, time: 0.750) loss: 0.000340 \n",
      "(epoch:  22, iters:      200, time: 0.750) loss: 0.000325 \n",
      "(epoch:  22, iters:      300, time: 0.750) loss: 0.000512 \n",
      "(epoch:  22, iters:      400, time: 0.751) loss: 0.000663 \n",
      "(epoch:  22, iters:      500, time: 0.755) loss: 0.000279 \n",
      "(epoch:  22, iters:      600, time: 0.754) loss: 0.000427 \n",
      "(epoch:  22, iters:      700, time: 0.752) loss: 0.000629 \n",
      "end of iteration 22\n",
      "(epoch:  23, iters:        0, time: 0.749) loss: 0.000240 \n",
      "(epoch:  23, iters:      100, time: 0.756) loss: 0.000380 \n",
      "(epoch:  23, iters:      200, time: 0.751) loss: 0.000361 \n",
      "(epoch:  23, iters:      300, time: 0.750) loss: 0.000571 \n",
      "(epoch:  23, iters:      400, time: 0.750) loss: 0.000618 \n",
      "(epoch:  23, iters:      500, time: 0.750) loss: 0.000328 \n",
      "(epoch:  23, iters:      600, time: 0.750) loss: 0.000574 \n",
      "(epoch:  23, iters:      700, time: 0.750) loss: 0.000620 \n",
      "end of iteration 23\n",
      "(epoch:  24, iters:        0, time: 0.750) loss: 0.000218 \n",
      "(epoch:  24, iters:      100, time: 0.750) loss: 0.000366 \n",
      "(epoch:  24, iters:      200, time: 0.750) loss: 0.000325 \n",
      "(epoch:  24, iters:      300, time: 0.751) loss: 0.000565 \n",
      "(epoch:  24, iters:      400, time: 0.751) loss: 0.000728 \n",
      "(epoch:  24, iters:      500, time: 0.750) loss: 0.000373 \n",
      "(epoch:  24, iters:      600, time: 0.749) loss: 0.000472 \n",
      "(epoch:  24, iters:      700, time: 0.751) loss: 0.000632 \n",
      "end of iteration 24\n",
      "(epoch:  25, iters:        0, time: 0.750) loss: 0.000256 \n",
      "(epoch:  25, iters:      100, time: 0.756) loss: 0.000330 \n",
      "(epoch:  25, iters:      200, time: 0.749) loss: 0.000396 \n",
      "(epoch:  25, iters:      300, time: 0.751) loss: 0.000542 \n",
      "(epoch:  25, iters:      400, time: 0.751) loss: 0.000873 \n",
      "(epoch:  25, iters:      500, time: 0.754) loss: 0.000326 \n",
      "(epoch:  25, iters:      600, time: 0.751) loss: 0.000463 \n",
      "(epoch:  25, iters:      700, time: 0.752) loss: 0.000503 \n",
      "Start validation phase ...\n",
      "(epoch:  25, iters:      724, time: 339.955) psnr: 38.412736 \n",
      "Saving the model at the end of iteration 25\n",
      "end of iteration 25\n",
      "(epoch:  26, iters:        0, time: 0.751) loss: 0.000299 \n",
      "(epoch:  26, iters:      100, time: 0.749) loss: 0.000299 \n",
      "(epoch:  26, iters:      200, time: 0.749) loss: 0.000351 \n",
      "(epoch:  26, iters:      300, time: 0.751) loss: 0.000540 \n",
      "(epoch:  26, iters:      400, time: 0.750) loss: 0.000443 \n",
      "(epoch:  26, iters:      500, time: 0.750) loss: 0.000301 \n",
      "(epoch:  26, iters:      600, time: 0.751) loss: 0.000478 \n",
      "(epoch:  26, iters:      700, time: 0.750) loss: 0.000576 \n",
      "end of iteration 26\n",
      "(epoch:  27, iters:        0, time: 0.750) loss: 0.000258 \n",
      "(epoch:  27, iters:      100, time: 0.750) loss: 0.000377 \n",
      "(epoch:  27, iters:      200, time: 0.750) loss: 0.000312 \n",
      "(epoch:  27, iters:      300, time: 0.749) loss: 0.000556 \n",
      "(epoch:  27, iters:      400, time: 0.751) loss: 0.000567 \n",
      "(epoch:  27, iters:      500, time: 0.750) loss: 0.000305 \n",
      "(epoch:  27, iters:      600, time: 0.750) loss: 0.000468 \n",
      "(epoch:  27, iters:      700, time: 0.751) loss: 0.000551 \n",
      "end of iteration 27\n",
      "(epoch:  28, iters:        0, time: 0.751) loss: 0.000205 \n",
      "(epoch:  28, iters:      100, time: 0.750) loss: 0.000374 \n",
      "(epoch:  28, iters:      200, time: 0.750) loss: 0.000370 \n",
      "(epoch:  28, iters:      300, time: 0.750) loss: 0.000570 \n",
      "(epoch:  28, iters:      400, time: 0.751) loss: 0.000570 \n",
      "(epoch:  28, iters:      500, time: 0.749) loss: 0.000308 \n",
      "(epoch:  28, iters:      600, time: 0.752) loss: 0.000488 \n",
      "(epoch:  28, iters:      700, time: 0.751) loss: 0.000642 \n",
      "end of iteration 28\n",
      "(epoch:  29, iters:        0, time: 0.750) loss: 0.000244 \n",
      "(epoch:  29, iters:      100, time: 0.750) loss: 0.000421 \n",
      "(epoch:  29, iters:      200, time: 0.750) loss: 0.000340 \n",
      "(epoch:  29, iters:      300, time: 0.749) loss: 0.000481 \n",
      "(epoch:  29, iters:      400, time: 0.750) loss: 0.000546 \n",
      "(epoch:  29, iters:      500, time: 0.750) loss: 0.000308 \n",
      "(epoch:  29, iters:      600, time: 0.750) loss: 0.000527 \n",
      "(epoch:  29, iters:      700, time: 0.750) loss: 0.000736 \n",
      "end of iteration 29\n",
      "(epoch:  30, iters:        0, time: 0.751) loss: 0.000268 \n",
      "(epoch:  30, iters:      100, time: 0.749) loss: 0.000325 \n",
      "(epoch:  30, iters:      200, time: 0.750) loss: 0.000335 \n",
      "(epoch:  30, iters:      300, time: 0.750) loss: 0.000546 \n",
      "(epoch:  30, iters:      400, time: 0.751) loss: 0.000533 \n",
      "(epoch:  30, iters:      500, time: 0.748) loss: 0.000282 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# run this model\n",
    "start_time = time.time()\n",
    "\n",
    "val_size = len(valid_set)\n",
    "depth = 624\n",
    "\n",
    "for iteration in range(opt['train']['niter']+1):\n",
    "    for i, train_data in enumerate(training_set):\n",
    "        train_start_time = time.time()\n",
    "        # training\n",
    "        model.feed_data(train_data)\n",
    "        model.optimize_parameters(i)\n",
    "        train_duration = time.time() - train_start_time\n",
    "        \n",
    "        # print losses\n",
    "        if i % opt['logger']['print_freq'] == 0:\n",
    "          losses = model.get_current_losses()\n",
    "          logger.print_results(losses, iteration, i, train_duration, 'loss')\n",
    "\n",
    "    if iteration != 0:\n",
    "        # validation\n",
    "        if iteration % opt['train']['val_freq'] == 0:\n",
    "          validate(valid_set, val_size, depth, model, logger, iteration, i)\n",
    "\n",
    "        # save\n",
    "        if iteration % opt['logger']['save_checkpoint_freq'] == 0:\n",
    "            print('Saving the model at the end of iteration %d' % (iteration))\n",
    "            model.save(iteration)\n",
    "\n",
    "    print('end of iteration ' + str(iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gv5sz5zKGxy"
   },
   "source": [
    "Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1595495060120,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "Vf_imKPY-Vlc",
    "outputId": "3647c9de-60a6-4a7a-a0aa-4226b6e62a90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# run this model\n",
    "start_time = time.time()\n",
    "\n",
    "val_size = len(valid_set)\n",
    "depth = 624\n",
    "\n",
    "for iteration in range(opt['train']['niter']+1):\n",
    "    for i, train_data in enumerate(training_set):\n",
    "        train_start_time = time.time()\n",
    "        # training\n",
    "        model.feed_data(train_data)\n",
    "        model.optimize_parameters(i)\n",
    "        train_duration = time.time() - train_start_time\n",
    "        \n",
    "        # print losses\n",
    "        if i % opt['logger']['print_freq'] == 0:\n",
    "          losses = model.get_current_losses()\n",
    "          logger.print_results(losses, iteration, i, train_duration, 'loss')\n",
    "\n",
    "    if iteration != 0:\n",
    "        # validation\n",
    "        if iteration % opt['train']['val_freq'] == 0:\n",
    "          validate(valid_set, val_size, depth, model, logger, iteration, i)\n",
    "\n",
    "        # save\n",
    "        if iteration % opt['logger']['save_checkpoint_freq'] == 0:\n",
    "            print('Saving the model at the end of iteration %d' % (iteration))\n",
    "            model.save(iteration)\n",
    "\n",
    "    print('end of iteration ' + str(iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1302,
     "status": "ok",
     "timestamp": 1595499380780,
     "user": {
      "displayName": "Sibo Cheng",
      "photoUrl": "",
      "userId": "11821944042190821232"
     },
     "user_tz": -60
    },
    "id": "et8_-pD5K9Xx",
    "outputId": "c5477e59-104d-4b6e-967e-36d572141925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model for G [experiments/SRResNet_x4/trained_models/25_G.pth] ...\n"
     ]
    }
   ],
   "source": [
    "model.load_path_G = 'experiments/SRResNet_x4/trained_models/25_G.pth'\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "S9gESq7eSGv-",
    "outputId": "cdfd4402-e533-4c5d-8e9e-954fa14b5654"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch:  26, iters:        0, time: 0.765) loss: 0.000248 \n",
      "(epoch:  26, iters:      100, time: 0.751) loss: 0.000295 \n",
      "(epoch:  26, iters:      200, time: 0.751) loss: 0.000383 \n",
      "(epoch:  26, iters:      300, time: 0.762) loss: 0.000534 \n",
      "(epoch:  26, iters:      400, time: 0.753) loss: 0.000634 \n",
      "(epoch:  26, iters:      500, time: 0.763) loss: 0.000256 \n",
      "(epoch:  26, iters:      600, time: 0.756) loss: 0.000491 \n",
      "(epoch:  26, iters:      700, time: 0.755) loss: 0.000621 \n",
      "end of iteration 26\n",
      "(epoch:  27, iters:        0, time: 0.754) loss: 0.000257 \n",
      "(epoch:  27, iters:      100, time: 0.752) loss: 0.000336 \n",
      "(epoch:  27, iters:      200, time: 0.753) loss: 0.000332 \n",
      "(epoch:  27, iters:      300, time: 0.752) loss: 0.000484 \n",
      "(epoch:  27, iters:      400, time: 0.753) loss: 0.000490 \n",
      "(epoch:  27, iters:      500, time: 0.754) loss: 0.000280 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# run this model\n",
    "start_time = time.time()\n",
    "\n",
    "val_size = len(valid_set)\n",
    "depth = 624\n",
    "\n",
    "for iteration in range(26, 46):\n",
    "    for i, train_data in enumerate(training_set):\n",
    "        train_start_time = time.time()\n",
    "        # training\n",
    "        model.feed_data(train_data)\n",
    "        model.optimize_parameters(i)\n",
    "        train_duration = time.time() - train_start_time\n",
    "        \n",
    "        # print losses\n",
    "        if i % opt['logger']['print_freq'] == 0:\n",
    "          losses = model.get_current_losses()\n",
    "          logger.print_results(losses, iteration, i, train_duration, 'loss')\n",
    "\n",
    "    if iteration != 0:\n",
    "        # validation\n",
    "        if iteration % opt['train']['val_freq'] == 0:\n",
    "          validate(valid_set, val_size, depth, model, logger, iteration, i)\n",
    "\n",
    "        # save\n",
    "        if iteration % opt['logger']['save_checkpoint_freq'] == 0:\n",
    "            print('Saving the model at the end of iteration %d' % (iteration))\n",
    "            model.save(iteration)\n",
    "\n",
    "    print('end of iteration ' + str(iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odcSxJv0K5t7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMXF0tvketT6NQbTCbNzd4g",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "brain_resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
